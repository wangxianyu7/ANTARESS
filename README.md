# **A**dvanced and **N**eat **T**echniques for the **A**ccurate **R**etrieval of **E**xoplanetary and **S**tellar **S**pectra

Read the documentation [here](https://obswww.unige.ch/~bourriev/antaress/doc/html/).

## General approach

First, define the system properties for the host star and its planets in [ANTARESS_systems.py](ANTARESS_systems.py).  
Then, define your input datasets, and the modules to process and analyze them, in a copy of the default configuration file [ANTARESS_settings.py](ANTARESS_settings.py). You can name your own configuration file as `ANTARESS_settings_username.py`.  
Finally, launch the workflow with the python command `ANTARESS_launcher(user = username)`. 

Most fields in the configuration file have default values. However, we recommend you try out changing their values to process your specific datasets.

Modules are grouped in three main categories:
- [ ] Data first go through formatting and correction modules, some of which are specific to given instruments. Once data are set in the common ANTARESS format and corrected for instrumental/environmental effects, they can be processed in the same way by the subsequent modules. 
- [ ] The second group of modules are thus generic and aim at extracting specific types of spectral profiles, converting them in the format required for the analysis chosen by the user. 
- [ ] The third group of modules allow fitting the processed spectral profiles to derive quantities of interest. 

Modules in the first and second group are ran successively, ie that data need to be processed by an earlier module before it can be used by the next one. 

Analyses modules, in contrast, are applied to the outputs of various processing modules throughout the pipeline. 

Some of the correction and processing modules are optional, for example the telluric correction module for space-borne data or the flux scaling module for data with absolute photometry. 

Some modules are only activated if the pipeline is used for a specific goal, for example the conversion of stellar spectra into CCFs when the user requires the analysis of the Rossiter-McLaughlin effect.

Each module can be activated independently 
- in most modules you can choose to calculate data (in which case it will then be automatically saved on disk) or to retrieve it (in which case the pipeline will check these data already exists)
- keeping all data in memory is not possible when processing e2ds, which is why the pipeline works in each module by retrieving the relevant data from the disk

## Plots

Plots are generated at the end of the workflow processing, upon request.

At the end of each module settings in the configuration file, you can activate a given `plot_name` by setting `plot_dic['plot_name']` to a figure extension, such as `pdf`.

The plot settings are then controlled through the plot configuration file, `ANTARESS_plot_settings.py`.

Because plots may require specific outputs of large size, the latter are not generated by default. This means you need to activate the plot as described above for the workflow to save the required outputs when the module is ran.

## Notebooks

Notebooks allow you to run a simplified version of the ANTARESS workflow. Their purpose is to help you familiarize with ANTARESS. To exploit the workflow to its full capabilities, use the configuration file.  

Notebooks available in the namesake [directory](Notebooks/):
- [ANTARESS_nbook_mock](Notebooks/ANTARESS_nbook_mock.ipynb) : to generate a mock CCF dataset

## Required packages
- [ ] run `pip install` with [scipy](https://scipy.org/), lmfit, batman-package, astropy, emcee, pathos, pandas, dace_query, statsmodels, PyAstronomy        
- [ ] resampling package 
- [bindensity documentation](https://obswww.unige.ch/~delisle/staging/bindensity/doc/)
- run `pip install --extra-index-url https://vincent:cestpasfaux@obswww.unige.ch/~delisle/staging bindensity --upgrade`
- do not use routines with non-continuous tables, as it will mess up with banded covariance matrixes
- beware of masking ranges, as undefined pixels (set to nan values) are propagated when resampling or combining profiles in the various pipeline modules.
- [ ] pySME
- follow these instructions to install PySME on M1/M2 Macs.
  - install rosetta by running `softwareupdate --install-rosetta`
  - install Homebrew under rosetta by running  
`$ arch -x86_64 /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"` 
This installs Homebrew under  
`/usr/local/bin/brew`   
instead of the default for arm64  
`/opt/homebrew/bin/brew`
  - install gcc@9 (see [documentation](https://tenderlovemaking.com/2022/01/07/homebrew-rosetta-and-ruby.html )) by running
`$ arch -x86_64 /usr/local/bin/brew install gcc@9`
  - create a Conda environment to run under the intel x64_86 architecture (see [documentation](https://abpcomputing.web.cern.ch/guides/apple_silicon/)) and install PySME in this environment   
`CONDA_SUBDIR=osx-64 conda create -n envname python=3.11`
then 
`pip install pysme-astro`
- follow these instructions to install PySME on older Macs
  - install gcc9 with `brew install gcc@9`
  - run `pip install pysme-astro`

- [ ] KitCat
- install [gsl](https://www.gnu.org/software/gsl/) with `brew install gsl`
- run `python setup_lbl_fit.py build` after setting up the path to your local python installation in the [setup_lbl_fit.py](ANTARESS_masks/KitCat/setup_lbl_fit.py). Then copy the compiled file `calculate_RV_line_by_line3.cpython-XX-darwin.so` into your ANTARESS/KitCat directory  

## Contributors
Omar Attia, Romain Allart, Khaled Al Moulla, Vincent Bourrier, Heather Cegla, Michaël Cretignier, William Dethier, Jean-Baptiste Delisle, Xavier Dumusque, David Ehrenreich, Erik Fridén, Nathan Hara, Christophe Lovis, Samson Jules Mercier, Dany Mounzer, Francesco Alfonso Pepe, Julia Victoria Seidel, Michal Steiner, Sara Tavella, Valentina Vaulato, Theo Vrignaud, Aurélien Wyttenbach.

## References
TBD

## Contribute
You are welcome to open issues and/or contribute code via pull-requests after signing in to your [SWITCH edu-ID account](https://gitlab.unige.ch).
If you do not have an account, [create one](https://eduid.ch) and then [sign in](https://gitlab.unige.ch) by selecting "SWITCH edu-ID" as your organisation.

You can contact [Vincent Bourrier](mailto:vincent.bourrier@unige.ch) if you are interested in collaborations and developments of this project. 

